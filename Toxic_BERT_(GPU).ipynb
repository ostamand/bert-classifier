{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic BERT (GPU).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ostamand/bert-classifier/blob/master/Toxic_BERT_(GPU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsIyvG30p9Y5",
        "colab_type": "text"
      },
      "source": [
        "# Toxic BERT (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRfZbnCPqdyR",
        "colab_type": "text"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCrx9J4sWGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbDoct7BYqfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwHBHnZ3Yuru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu>=1.11.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MpVCqmOp3Ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/google-research/bert bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iOIU5jmPYju",
        "colab_type": "text"
      },
      "source": [
        "## Setup TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP38eqLXcd62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCPDGT_AWk8P",
        "colab_type": "text"
      },
      "source": [
        "Start tensorboad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5r3Pu_hPcCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir tmp/ --host 0.0.0.0 --port 6006 &'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bAsMOdnPrDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYd-bheVPs9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8WQsktGWYrO",
        "colab_type": "text"
      },
      "source": [
        "To restart tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnsWPrAPWCzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1EaHXWKYJMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 3025"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfmL7HGWfyJh",
        "colab_type": "text"
      },
      "source": [
        "Tensorboard debugging commands:\n",
        "\n",
        "`!find ./tmp | grep tfevents`\n",
        "\n",
        "`!tensorboard --inspect --logdir tmp`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPWtREoNbHLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWzrrULDXord",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGuyv85aPzov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTyD0nqqhgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.insert(0, 'bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_7AsRiYqwBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "\n",
        "import modeling\n",
        "import optimization\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "from run_classifier_with_tfhub import create_tokenizer_from_hub_module\n",
        "from run_classifier import convert_examples_to_features, DataProcessor, InputExample\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWNYN3dDNnnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUTTjJajpZ3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mVIV4HsrzAf",
        "colab_type": "text"
      },
      "source": [
        "## Setup gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMXm-9jD6V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zUwgLZGr3nh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlhyyo2LO6J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    self.lr = 2e-5\n",
        "    self.aux_targets=6\n",
        "    self.module_handle = 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
        "    self.maxlen = 220 \n",
        "    self.bs = 8\n",
        "    self.epochs = 1\n",
        "    \n",
        "config = Config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jogaq2-01OUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToxicProcessor(DataProcessor):\n",
        "  \n",
        "  def __init__(self, num_to_load=None):\n",
        "    self.num_to_load = num_to_load\n",
        "    self.label_list = ['0', '1']\n",
        "  \n",
        "  def get_train_examples(self, data_dir):\n",
        "    df = self._read_csv(os.path.join(data_dir, 'train.csv'))\n",
        "    if self.num_to_load:\n",
        "      df = df.iloc[:self.num_to_load]\n",
        "    df['comment_text'].astype(str)\n",
        "    examples = []\n",
        "    for i, row in df.iterrows():\n",
        "      guid = f\"train-{i}\"\n",
        "      label = '1' if row['target'] >= 0.5 else '0'\n",
        "      text_a = str(row['comment_text'])\n",
        "      examples.append(\n",
        "          InputExample(guid=guid, text_a=text_a, text_b=None, label=label)\n",
        "      )\n",
        "    return examples\n",
        "  \n",
        "  @classmethod\n",
        "  def _read_csv(cls, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR5ZK8-C1IgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(config, input_ids, input_mask, segment_ids, label_ids):\n",
        "  tags = set()\n",
        "  tags.add('train')\n",
        "  \n",
        "  with tf.variable_scope('bert'):\n",
        "    bert_module = hub.Module('https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1', tags=tags, trainable=True)\n",
        "    bert_inputs = dict(\n",
        "          input_ids=input_ids,\n",
        "          input_mask=input_mask,\n",
        "          segment_ids=segment_ids\n",
        "    )\n",
        "    bert_outputs = bert_module(\n",
        "          inputs=bert_inputs,\n",
        "          signature=\"tokens\",\n",
        "          as_dict=True\n",
        "    )\n",
        "    output_layer = bert_outputs[\"pooled_output\"]\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "  \n",
        "  # classifier layers on top of BERT\n",
        "  \n",
        "  with tf.variable_scope(\"classifier\"):\n",
        "    fc_weights = tf.get_variable(\n",
        "        \"fc_weights\", [1, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02)\n",
        "    )\n",
        "\n",
        "    fc_aux_weights = tf.get_variable(\n",
        "        \"fc_aux_weights\", [6, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02)\n",
        "    )\n",
        "\n",
        "    fc_bias = tf.get_variable(\n",
        "        \"fc_bias\", [1], initializer=tf.zeros_initializer()\n",
        "    )\n",
        "\n",
        "    fc_aux_bias = tf.get_variable(\n",
        "        \"fc_aux_bias\", [6], initializer=tf.zeros_initializer()\n",
        "    )\n",
        "    \n",
        "    output_layer = tf.nn.dropout(output_layer, rate=0.4)\n",
        "    logits_fc = tf.matmul(output_layer, fc_weights, transpose_b=True)\n",
        "    logits_fc = tf.nn.bias_add(logits_fc, fc_bias)\n",
        "    \n",
        "    # not used for now, for custom loss calculation \n",
        "    logits_fc_aux = tf.matmul(output_layer, fc_aux_weights, transpose_b=True)\n",
        "    logits_fc_aux = tf.nn.bias_add(logits_fc_aux, fc_aux_bias)\n",
        "    \n",
        "    logits = tf.concat([logits_fc, logits_fc_aux], axis=1, name='logits')\n",
        "    \n",
        "    # for now, use only labels \n",
        "    probs = tf.nn.sigmoid(logits_fc, name='probs')\n",
        "    \n",
        "    preds = tf.squeeze(tf.cast((probs >= 0.5), tf.float32), name='preds')\n",
        "    \n",
        "    logits_for_loss = tf.reshape(tf.slice(logits, [0, 0] , [-1, 1]), [-1])\n",
        "    \n",
        "    labels = tf.cast(label_ids, tf.float32, name='labels')\n",
        "    \n",
        "    eval_op = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels, predictions=preds)\n",
        "    }\n",
        "    \n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.math.equal(preds, labels), tf.float32), name='accuracy')\n",
        "    tf.summary.scalar('accuracy', accuracy)\n",
        "    \n",
        "  with tf.variable_scope(\"optimizer\"):\n",
        "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      labels=labels,\n",
        "      logits=logits_for_loss\n",
        "    )\n",
        "    loss = tf.reduce_mean(loss, name='loss')\n",
        "    train_op = optimization.create_optimizer(loss, config.lr, config.num_train_steps, config.num_warmup_steps, False)\n",
        "    \n",
        "  return loss, train_op, eval_op, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_NC6U61WdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(features, seq_length, batch_size, mode):\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "  \n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "    \n",
        "  num_examples = len(features)\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "    })\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(buffer_size=100)\n",
        "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
        "  elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False)\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfiCBnY1XgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ref: https://www.tensorflow.org/guide/custom_estimators\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "  input_ids = features[\"input_ids\"]\n",
        "  input_mask = features[\"input_mask\"]\n",
        "  segment_ids = features[\"segment_ids\"]\n",
        "  label_ids = features[\"label_ids\"]\n",
        "    \n",
        "  loss, train_op, eval_op, accuracy = build_model(\n",
        "      params['config'],\n",
        "      input_ids, \n",
        "      input_mask,\n",
        "      segment_ids,\n",
        "      label_ids\n",
        "  )\n",
        "    \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    spec = tf.estimator.EstimatorSpec(\n",
        "        mode=tf.estimator.ModeKeys.TRAIN,\n",
        "        loss=loss,\n",
        "        train_op=train_op\n",
        "    )\n",
        "  elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "    spec = tf.estimator.EstimatorSpec(\n",
        "        mode=mode, \n",
        "        loss=loss, \n",
        "        eval_metric_ops=eval_op\n",
        "    )\n",
        "    \n",
        "  return spec  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anfsDZ8h1sYe",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jbL5j8eP_Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processor = ToxicProcessor(num_to_load=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl724M9WHhNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples = processor.get_train_examples('gdrive/My Drive/code/jigsaw-bias-toxicity/data/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p-lae7Iwc79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = create_tokenizer_from_hub_module(config.module_handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WzwqqyCz4M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = convert_examples_to_features(examples, processor.label_list, config.maxlen, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LlztNGiOo_k",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Xo8kTIexX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config=Config()\n",
        "config.num_train_steps =  int(len(features) / config.bs * config.epochs)\n",
        "config.num_warmup_steps = int(config.num_train_steps * 0.05)\n",
        "\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    log_step_count_steps=10,\n",
        "    save_summary_steps=10\n",
        ")\n",
        "  \n",
        "classifier = tf.estimator.Estimator(\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    params={\n",
        "        'config': config},\n",
        "    model_dir='tmp'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSO4xNxiU7ir",
        "colab_type": "text"
      },
      "source": [
        "`%tensorboard --logdir tmp/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZWUAwwJZ7TL",
        "colab_type": "text"
      },
      "source": [
        "To delete previous run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rttCTEyUqDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r -f tmp/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Yk8TcHZ-VU",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SCra-nofb6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(features, config.maxlen, config.bs, tf.estimator.ModeKeys.TRAIN),\n",
        "    max_steps=config.num_train_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQpJGcdPHoHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(features, config.maxlen, config.bs, tf.estimator.ModeKeys.EVAL)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrQWn2eLXGpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_result"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}